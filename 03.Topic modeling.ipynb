{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b86f878-f80d-4584-bddd-334c13d7bdc1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95aba65-debe-47b7-99df-57c1bf48be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARY\n",
    "# For decompressing and processing data\n",
    "import zstandard\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import logging.handlers\n",
    "\n",
    "# For scraping Reddit submissions\n",
    "!pip install praw\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# For data cleaning and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Import NLTK for text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Import the sentiment analysis tool\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Install and load the SpaCy package\n",
    "!pip install spacy\n",
    "import spacy\n",
    "\n",
    "# Download and install the SpaCy English language model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# For topic modeling\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# For temporal analysis visualization\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# For date formatting in charts\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# For interactive visualization\n",
    "import plotly.express as px\n",
    "\n",
    "import ast\n",
    "\n",
    "# For statistic test \n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.proportion import proportions_ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c9778-0742-429a-bb76-e540ae34d4c0",
   "metadata": {},
   "source": [
    "## 3.Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd353b1-538b-48fb-a3f8-eefe94169978",
   "metadata": {},
   "source": [
    "This section of the code includes:\n",
    "\n",
    "- a. Build dictionary and BOW corpus for LDA model.\n",
    "- b. Test the optimal topics numbers from 5 to 30.\n",
    "- c. Run the LDA model with the optimal topic numbers.\n",
    "- d. Temporal analysis by topics by five themes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b88ee1-3e50-4686-b780-07a66c9ff0fa",
   "metadata": {},
   "source": [
    "### a. Build dictionary and BOW corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889c7b8-aeac-44cb-bc71-86f9ea78e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset for LDA analysis\n",
    "preprocessed_lda = pd.read_csv('/Users/Desktop/Reddit data/preprocessed_lda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e8ebb-5373-4578-bf68-6e7a5b38ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert the post text to string\n",
    "lda_texts = preprocessed_lda['Selftext'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edf7d7-5c03-407f-9837-89d4be1e7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [[word for word in word_tokenize(doc) if word.lower() not in stop_words] for doc in lda_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511fdebe-e380-42b4-8b67-b4ce8c1c7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.8) # Filter extreme words in the dictionary\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cb496-eea3-4245-bb97-3d6553958c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a43541-f446-42fc-9f1a-2d0270ea666f",
   "metadata": {},
   "source": [
    "### b. Test the optimal topic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c030b-6de3-44d2-9ef7-4001f7a19ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the number of different topics\n",
    "topic_numbers = range(5, 31, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039c144-d7dd-46ec-9b79-2ec821af019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list of coherence scores\n",
    "c_v_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c6958-9181-4dce-8254-a99353332a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LDA multicore model\n",
    "alpha = 1  # Hyperparameter for document-topic distribution\n",
    "beta = 0.1  # Hyperparameter for topic-word distribution\n",
    "random_state = 42  # Random state for reproducibility\n",
    "workers = 3  # Number of CPUs to use\n",
    "passes = 20  # Number of passes through the corpus\n",
    "iterations = 1000 # interation 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991755c9-be36-477c-8b59-4d036d85bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the optimal topics\n",
    "for num_topics in topic_numbers:\n",
    "    lda_model = LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics, alpha=alpha, eta=beta, workers=workers, passes=passes, random_state=random_state, iterations=iterations)\n",
    "    c_v_model = CoherenceModel(model=lda_model, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
    "    c_v_lda = c_v_model.get_coherence()\n",
    "    c_v_scores.append(c_v_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31acf6-78f1-447f-8103-3f4a444af318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency scores visualization\n",
    "\n",
    "# Convert the range object to a list\n",
    "topic_numbers = range(5, 31)\n",
    "\n",
    "# Plot Pre-pandemic consistency scores\n",
    "plt.plot(topic_numbers, c_v_scores, label='Coherence Score')\n",
    "plt.axvline(x=16, color='red', linestyle='--', label='Selected Topic Number')\n",
    "\n",
    "# Add legend in the upper right corner and reduce its size\n",
    "plt.legend(loc='lower right', prop={'size': 8})\n",
    "\n",
    "plt.xticks([5, 10, 15, 20, 25, 30])  # Set the ticks of x-axis\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Coherence Score')\n",
    "plt.grid(True, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('consistency_scores_plot.png', dpi=300, bbox_inches='tight')  # Save as PNG with high resolution\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0535ef8-f15e-4b8a-9202-d1792a43dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence_score with number of topics\n",
    "for num_topics, coherence_score in zip(topic_numbers, c_v_scores):\n",
    "    print(f'The model with num_topics = {num_topics} has a coherence value of {coherence_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50ab21-a25c-4b27-a384-059f76d2194e",
   "metadata": {},
   "source": [
    "### c. Run the LDA model with the 16 topic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b3835-caed-4a66-87e8-d48ad7773bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build new dictionary and BOW corpus\n",
    "\n",
    "# Add Custom stop words\n",
    "custom_stop_words = set(['get','make','take','really','still','even','also','try','see','thing', 'new', 'end', 'much'])\n",
    "\n",
    "# Tokenize new text\n",
    "tokenized_texts_16 = [[word for word in word_tokenize(doc) if word.lower() not in custom_stop_words] for doc in lda_texts]\n",
    "\n",
    "# Create new dictionary\n",
    "dictionary_16 = corpora.Dictionary(tokenized_texts_16)\n",
    "dictionary_16.filter_extremes(no_below=5, no_above=0.8)\n",
    "\n",
    "# Create new dictionary\n",
    "corpus_16 = [dictionary_16.doc2bow(doc) for doc in tokenized_texts_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e2131-bff3-4e49-98d2-4859339a0cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rerun the LDA model\n",
    "lda_model_16 = LdaMulticore(corpus=corpus_16,\n",
    "                         id2word=dictionary_16,\n",
    "                         num_topics=16,\n",
    "                         alpha=alpha,\n",
    "                         eta=beta,\n",
    "                         random_state=random_state,\n",
    "                         workers=workers,\n",
    "                         iterations = iterations,\n",
    "                         passes=passes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32039b6-7dc2-49b9-8209-14e4a3fa3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each topic number and its associated words\n",
    "for idx, topic in lda_model_16.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde5732-5965-439c-9fb6-57f340b523fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new coherence score for the re-run LDA model\n",
    "coherence_lda_model_16 = CoherenceModel(model=lda_model_16, texts=tokenized_texts_16, dictionary=dictionary_16, coherence='c_v')\n",
    "coherence_lda_16 = coherence_lda_model_16.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b4923-5cdd-4a07-9b1b-e028f80dff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic distribution for each document in the corpus\n",
    "doc_topics = [lda_model_16.get_document_topics(doc) for doc in corpus_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d852899-f796-4943-b1ef-fcdb675604cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the topic with the highest probability for each document\n",
    "relevant_topics = [max(doc, key=lambda x: x[1])[0] for doc in doc_topics] # contains the most relevant topic ID for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56395183-54f5-4d54-a81d-1a68eb14b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Topic' to the DataFrame\n",
    "preprocessed_lda['Topic'] = relevant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86825bfb-a9ee-4e0d-890d-8b3146bc29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26205d56-7a5b-41a3-bdd9-c981b23a76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_submissions = preprocessed_lda.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20153b2-575e-46e1-a260-8ee612c5d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51ea17-76c1-4000-960d-438a714e2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_submissions.to_csv('/Users/Desktop/Reddit data/lda_submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91f3b7-62c2-4459-b9e7-90ca07c7f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the proportions of each topic\n",
    "topic_counts_total = lda_submissions['Topic'].value_counts() # the total number of posts of each topic\n",
    "topic_proportions_total = topic_counts_total / topic_counts_total.sum() * 100 # the proportions of each topic\n",
    "topic_proportions_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe4fc1-d987-4047-9dbb-88dacec41c39",
   "metadata": {},
   "source": [
    "### d. Temporal topics by themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83138d60-899c-4cd8-8c06-5947313394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Date' is the name of the column containing datetime information\n",
    "lda_submissions['Creation Time'] = pd.to_datetime(lda_submissions['Creation Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a7f39-8754-45f9-8f9b-69f1734e899a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of posts in each topic by two periods\n",
    "topic_counts = lda_submissions.groupby(['Period', 'Topic']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportions of posts in each topic by two periods\n",
    "total_posts = lda_submissions.shape[0] # total posts for the dataset\n",
    "topic_counts = topic_counts.stack().reset_index(name='Count') # posts in each topic by two periods\n",
    "topic_proportions = topic_counts.copy()\n",
    "topic_proportions['Proportion'] = (topic_proportions['Count'] / total_posts) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492055fb-0fd6-4742-98d1-925858d5b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'Creation Time' column as the index\n",
    "lda_submissions.set_index('Creation Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca245a-cb29-4929-af3e-6536ef2af1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the resample method to resample by month and calculate the number of posts\n",
    "monthly_posts = lda_submissions.resample('M').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2a517-0356-40b3-bc1e-e9ceb6d872f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the expected proportions for each topic\n",
    "topic_proportion = pd.DataFrame(index=monthly_posts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0483a0d-9a13-4d32-8167-6dfae0ba266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected proportion for each topic\n",
    "for topic in lda_submissions['Topic'].unique():\n",
    "    # Filter data for the specific topic and resample by month\n",
    "    monthly_topic_posts = lda_submissions[lda_submissions['Topic'] == topic].resample('M').size()\n",
    "    # Calculate the proportion by dividing the number of posts for each topic by the total number of posts for each month\n",
    "    topic_proportion[topic] = monthly_topic_posts / monthly_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff6f38-6f24-4ab2-9cc3-48ec84d4456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the topic counts to get proportions\n",
    "topic_proportion = topic_proportion.div(topic_proportion.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff99ee8-5b1b-412a-b59b-6018e022768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88088b23-a8b0-478c-951b-17022a2b8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic trends over time\n",
    "def plot_topic_trends(topic_proportion, topics_to_plot, names):\n",
    "    # Convert the time index (date) to a number\n",
    "    dates_numeric = np.arange(len(topic_proportion.index))\n",
    "\n",
    "    # Ensure the topic_proportion index is adjusted to the start of each month\n",
    "    adjusted = topic_proportion.index - pd.offsets.MonthEnd(1) + pd.Timedelta(days=1)\n",
    "\n",
    "    # Set the figure size\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    # Loop through each topic to plot\n",
    "    for i, topic in enumerate(topics_to_plot):\n",
    "            # Get the expected ratio sequence of the current theme\n",
    "            y = topic_proportion[topic].values * 100\n",
    "            # Apply LOESS regression\n",
    "            lowess_results = sm.nonparametric.lowess(y, dates_numeric, frac=0.4) # frac parameter controls the smoothness\n",
    "            # Draw the original data points\n",
    "            plt.scatter(adjusted, y, alpha=0.4, s=8)\n",
    "            # Draw the smooth curve\n",
    "            plt.plot(adjusted, lowess_results[:, 1], label=names[i], lw=1.5)\n",
    "\n",
    "    # Mark the pandemic start point with a vertical line\n",
    "    plt.axvline(x=adjusted[12], color='red', linestyle='--', label='Pandemic start point')\n",
    "    plt.ylabel('Topic Proportion', fontsize=18)\n",
    "    plt.gca().yaxis.set_major_formatter(FuncFormatter(lambda y, _: '{:.0f}%'.format(y))) # format y-axis as percentages\n",
    "\n",
    "    # Ensure x-axis shows every month\n",
    "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    plt.tick_params(axis='both', which='both', length=0) # remove the small tick lines on x and y axes\n",
    "    plt.legend(loc='upper right', fontsize=10) # add legend\n",
    "    plt.xticks(rotation=45, fontsize=13)  # rotate x-axis labels\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, color='lightgray')  # add grid\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457a5ea-2fde-46b8-864a-dfcfa7e9b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weight management theme\n",
    "topics_to_plot_1 = [2, 11, 9, 1]\n",
    "names_1 = ['Weight change (T2)', 'Weight loss goal (T11)', 'Medication (T9)', 'Daily updates(T1)']\n",
    "plot_topic_trends(topic_proportion, topics_to_plot_1, names_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e54926-a61e-4672-878a-be628a3a06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Diet theme\n",
    "topics_to_plot_2 = [10, 12, 3, 14]\n",
    "names_2 = ['Emotional eating (T10)', 'Food choice (T12)', 'Calorie tracker (T3)', 'Diet control(T14)']\n",
    "plot_topic_trends(topic_proportion, topics_to_plot_2, names_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04dd618-8748-4303-a2e2-fce59d7b4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Physical Exercise theme\n",
    "topics_to_plot_3 = [4, 15, 5, 6]\n",
    "names_3 = ['Motivation (T4)', 'Workout plan (T15)', 'Fitness App (T5)', 'Exercise routine (T6)']\n",
    "plot_topic_trends(topic_proportion, topics_to_plot_3, names_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0fb2f-7044-43a7-8104-32b7c3882d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Emotions and support theme\n",
    "topics_to_plot_4 = [13, 8]\n",
    "names_4 = ['Negative feelings (T13)', 'Seeking advice (T8)']\n",
    "plot_topic_trends(topic_proportion, topics_to_plot_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763a52b-9aaa-467b-a5f0-438943a05d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Appearance theme\n",
    "topics_to_plot_5 = [7, 0]\n",
    "names_5 = ['Body image (T7)', 'Clothe fit (T0)']\n",
    "plot_topic_trends(topic_proportion, topics_to_plot_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
